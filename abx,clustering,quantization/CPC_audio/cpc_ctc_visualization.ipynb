{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cpc.feature_loader as fl\n",
    "import cpc.train as tr\n",
    "from cpc.dataset import AudioBatchData, findAllSeqs, filterSeqs, parseSeqLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(tr.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = '/pio/scratch/2/jch/wav2vec/runs/cpc_base/ls100_cpcctc_match12_pred8/checkpoint_199.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache /pio/data/zerospeech2021/LibriSpeech-wav/train-clean-100/_seqs_cache.txt successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 61141.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking length...\n",
      "Done, elapsed: 0.012 seconds\n",
      "Scanned 10 sequences in 0.01 seconds\n",
      "1 chunks computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining pool\n",
      "Joined process, elapsed=0.977 secs\n",
      "Loading checkpoint /pio/scratch/2/jch/wav2vec/runs/cpc_base/ls100_cpcctc_match12_pred8/checkpoint_199.pt\n",
      "LocArgs: Namespace(CPCCTC=True, CPCCTCLearnBlank=False, CPCCTCLossTemp=1.0, CPCCTCMasq='', CPCCTCNoNegsMatchWin=False, CPCCTCNormalizeEncs=False, CPCCTCNormalizePreds=False, CPCCTCNumMatched=12, CPCCTCSelfLoop=False, CPCCTCSkipBeg=0, CPCCTCSkipEnd=0, CTC=False, abspos=False, arMode='LSTM', batchSizeGPU=32, beta1=0.9, beta2=0.999, cpc_mode=None, debug=False, dropout=True, encoder_type='cpc', epsilon=1e-08, file_extension='.wav', hiddenEncoder=256, hiddenGar=256, ignore_cache=False, learningRate=0.0002, limitNegsInBatch=8, load=None, loadCriterion=False, logging_step=1000, max_size_loaded=4000000000, nEpoch=200, nGPU=2, nLevelsGRU=2, nLevelsPhone=1, nPredicts=8, n_process_loader=1, negativeSamplingExt=128, normMode='layerNorm', onEncoder=False, pathCheckpoint='/pio/scratch/2/jch/wav2vec/runs/cpc_base/ls100_cpcctc_match12_pred8', pathDB='/pio/data/zerospeech2021/LibriSpeech-wav/train-clean-100', pathPhone=None, pathTrain='/pio/scratch/2/jch/wav2vec/LibriSpeech100_labels_split/train_split.txt', pathVal='/pio/scratch/2/jch/wav2vec/LibriSpeech100_labels_split/test_split.txt', random_seed=300355287, restart=False, rnnMode='transformer', samplingType='samespeaker', save_step=5, schedulerRamp=10, schedulerStep=-1, sizeWindow=20480, speakerEmbedding=0, supervised=False)\n",
      "Loading the state dict at /pio/scratch/2/jch/wav2vec/runs/cpc_base/ls100_cpcctc_match12_pred8/checkpoint_199.pt\n",
      "!!!!!!!!!USING CPCCTC!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "cdata = fl.getCheckpointData(os.path.dirname(CP))\n",
    "_, _, args = cdata\n",
    "args.pathDB = '/pio/data/zerospeech2021/LibriSpeech-wav/train-clean-100'\n",
    "args.pathTrain = '/pio/scratch/2/jch/wav2vec/LibriSpeech100_labels_split/train_split.txt'\n",
    "args.pathVal = '/pio/scratch/2/jch/wav2vec/LibriSpeech100_labels_split/test_split.txt'\n",
    "args.pathPhone = '/pio/scratch/2/jch/wav2vec/LibriSpeech100_labels_split/converted_aligned_phones.txt'\n",
    "args.size_window = 20480\n",
    "\n",
    "seqNames, speakers = findAllSeqs(args.pathDB,\n",
    "                                 extension=args.file_extension,\n",
    "                                 loadCache=not args.ignore_cache)\n",
    "phone_labels, n_phones = parseSeqLabels(args.pathPhone)\n",
    "\n",
    "seq_val = filterSeqs(args.pathVal, seqNames)[:10]\n",
    "db_val = AudioBatchData(args.pathDB, args.size_window, seq_val,\n",
    "                        phone_labels, len(speakers))\n",
    "\n",
    "model, args.hiddenGar, args.hiddenEncoder = fl.loadModel([CP])\n",
    "assert args.speakerEmbedding == 0\n",
    "criterion = tr.loadCriterion(CP, model.gEncoder.DOWNSAMPLING, len(speakers), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "criterion.cpu()\n",
    "val_loader = db_val.getDataLoader(1, 'sequential', False, numWorkers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data, label = next(data_iter)\n",
    "c_feature, encoded_data, _ = model(batch_data, None)\n",
    "\n",
    "# cFeature: after the autoregressive model\n",
    "# encoded_data: output of the encoder\n",
    "\n",
    "losses, outAcc, captured = criterion(c_feature, encoded_data, label, captureOptions=['locals'])\n",
    "crit_locals = captured['locals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([116, 12, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_locals['log_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([116, 12, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_locals['log_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dca2419e1447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mO\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPCCTCNumMatched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrit_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrit_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aligns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPCCTCNumMatched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "O = 50\n",
    "print(label[0, O:O + args.CPCCTCNumMatched])\n",
    "plt.imshow(crit_locals['log_scores'][O].detach().numpy())\n",
    "plt.scatter(crit_locals['aligns'][O, :], np.arange(args.CPCCTCNumMatched))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
